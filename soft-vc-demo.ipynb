{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soft Speech Units for Improved Voice Conversion\n",
    "\n",
    "Demo for the paper: [A Comparison of Discrete and Soft Speech Units for Improved Voice Conversion](https://ieeexplore.ieee.org/abstract/document/9746484).\n",
    "\n",
    "- [Companion webpage](https://bshall.github.io/soft-vc/)\n",
    "- [Home repo](https://github.com/bshall/soft-vc)\n",
    "- [HuBERT content encoders](https://github.com/bshall/hubert)\n",
    "- [Acoustic Models](https://github.com/bshall/acoustic-model)\n",
    "- [HiFiGAN vocoder](https://github.com/bshall/hifigan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchaudio\n",
    "import requests\n",
    "import IPython.display as display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the HuBERT content encoder (either hubert_soft or hubert_discrete):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hubert = torch.hub.load(\"bshall/hubert:main\", \"hubert_soft\", trust_repo=True).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the acoustic model (either hubert_soft or hubert_discrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acoustic = torch.hub.load(\"bshall/acoustic-model:main\", \"hubert_soft\", trust_repo=True).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the vocoder (either hifigan_hubert_soft or hifigan_hubert_discrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hifigan = torch.hub.load(\"bshall/hifigan:main\", \"hifigan_hubert_soft\", trust_repo=True).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download an example utterance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"example.wav\", \"wb\") as file:\n",
    "  response = requests.get(\"https://drive.google.com/uc?export=preview&id=1Y3KuPAhB5VcsmIaokBVKu3LUEZOfhSu8\")\n",
    "  file.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or upload your own:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the source audio (and resample to 16kHz if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source, sr = torchaudio.load(\"example.wav\")\n",
    "source = torchaudio.functional.resample(source, sr, 16000)\n",
    "source = source.unsqueeze(0).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to the target speaker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    # Extract speech units\n",
    "    units = hubert.units(source)\n",
    "    # Generate target spectrogram\n",
    "    mel = acoustic.generate(units).transpose(1, 2)\n",
    "    # Generate audio waveform\n",
    "    target = hifigan(mel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets listen to the results!\n",
    "\n",
    "The source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Audio(source.squeeze().cpu(), rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the converted utterance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Audio(target.squeeze().cpu(), rate=16000)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "742fb0cf312e06021cb7ef6febc33961079fd3903e709e6dbd223a75c181bd01"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
